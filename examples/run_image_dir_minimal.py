# import time
# import glob
# import argparse
# from pathlib import Path

# import cv2
# import yaml
# import numpy as np
# import quaternion

import pym3t



# def parse_script_input():
#     parser = argparse.ArgumentParser(
#         prog='run_image_dir_example',
#         description='Run the m3t tracker image per image reading from rgb/depth folder'
#     )

#     parser.add_argument('-b', '--body_name',  dest='body_name',  type=str, required=True, help='Name of the object to track. need to match')
#     parser.add_argument('-m', '--models_dir', dest='models_dir', type=str, required=True, help='Path to directory where object model file {body_name}.obj is stored')
#     parser.add_argument('-c', '--cam_path',   dest='cam_path', type=str, required=True, help='Path to camera intrinsics file')
#     parser.add_argument('-i', '--imgs_dir',   dest='imgs_dir',   type=str, required=True, help='Path to directory where "rbg*" and "depth*" named images are stored')
#     parser.add_argument('-n', '--nb_img_load',     dest='nb_img_load',   type=int, default=-1)
#     parser.add_argument('-s', '--stop_at_each_img', dest='stop_at_each_img',   action='store_true', default=False)
#     parser.add_argument('--scale_geometry', dest='scale_geometry', default=0.001, type=float, required=False, help='Scale factor to convert model geometry to meters.')
#     parser.add_argument('--tmp_dir',    dest='tmp_dir',    type=str, default='tmp', help='Directory to store preprocessing files generated by the tracker.')
#     parser.add_argument('--use_region', dest='use_region', action='store_true', default=False)
#     parser.add_argument('--use_depth', dest='use_depth', action='store_true', default=False)
#     parser.add_argument('--use_texture', dest='use_texture', action='store_true', default=False)
#     parser.add_argument('--use_depth_viewer', dest='use_depth_viewer', action='store_true', default=False)
#     parser.add_argument('--model_occlusions', dest='model_occlusions', action='store_true', default=False)
#     parser.add_argument('--measure_occlusions', dest='measure_occlusions', action='store_true', default=False)

#     return parser.parse_args()

# args = parse_script_input()

# tmp_dir = Path(args.tmp_dir)
# tmp_dir.mkdir(exist_ok=True)

# # Load camera intrinsics from yaml file
# with open(args.cam_path, 'r') as f:
#     cam_intrinsics = yaml.load(f.read(), Loader=yaml.UnsafeLoader)


# synchronize_cameras: to be able to print elapsed time
# tracker = pym3t.Tracker('tracker', synchronize_cameras=False)
renderer_geometry = pym3t.RendererGeometry('renderer geometry')
renderer_geometry.SetUp()
import atexit
atexit.register(lambda: print("Python exiting"))

del renderer_geometry
print("OYO")
# renderer_geometry = pym3t.RendererGeometry('renderer geometry')
# print("OPPOPO")
# del renderer_geometry

# # Setup camera(s)
# color_camera = pym3t.DummyColorCamera('cam_color')
# color_camera.camera2world_pose = np.eye(4, dtype=np.float64)
# color_camera.intrinsics = pym3t.Intrinsics(**cam_intrinsics['intrinsics_color'])

# # Setup body model and properties
# obj_model_path = Path(args.models_dir) / f'{args.body_name}.obj'
# if not obj_model_path.exists(): raise ValueError(f'{obj_model_path} is a wrong path')
# print(f'Loading object {obj_model_path}')
# body = pym3t.Body(
#     name=args.body_name,
#     geometry_path=obj_model_path.as_posix(),
#     geometry_unit_in_meter=args.scale_geometry,
#     geometry_counterclockwise=1,
#     geometry_enable_culling=1,
#     geometry2body_pose=np.eye(4)
# )
# renderer_geometry.AddBody(body)
# renderer_geometry.DeleteBody(args.body_name)

# # Set up link: m3t handles polyarticulated systems but 
# # here we have only one link corresponding to the object with identity transform wrt to the body
# link = pym3t.Link(args.body_name + '_link', body)

# # Region Modality
# region_model_path = tmp_dir / (args.body_name + '_region_model.bin')
# region_model = pym3t.RegionModel(args.body_name + '_region_model', body, region_model_path.as_posix())
# region_modality = pym3t.RegionModality(args.body_name + '_region_modality', body, color_camera, region_model)
# link.AddModality(region_modality)

# optimizer = pym3t.Optimizer(args.body_name+'_optimizer', link)

# tracker.AddOptimizer(optimizer)

# color2world_pose = np.eye(4)
# color2world_pose[:3,:3] = quaternion.as_rotation_matrix(quaternion.from_rotation_vector([0.2,0.2,0.2]))
# color2world_pose[:3, 3] = np.array([0.2,0.2,0.2])
# color_camera.camera2world_pose = color2world_pose


# ok = tracker.SetUp()
# if not ok:
#     raise ValueError('tracker SetUp failed')

# ##############################


# imgs_dir = Path(args.imgs_dir)
# if not imgs_dir.exists():
#     print(f'Wrong path to image directory: {imgs_dir}')
# # read images from disk
# color_names = sorted(glob.glob((imgs_dir / 'color*').as_posix()))
# depth_names = sorted(glob.glob((imgs_dir / 'depth*').as_posix()))

# # load images from disk
# color_read_flags = cv2.IMREAD_COLOR + cv2.IMREAD_ANYDEPTH
# img_bgr_lst = [cv2.imread(name, color_read_flags) for name in color_names]  # loads a dtype=uint8 array
# depth_read_flags = cv2.IMREAD_GRAYSCALE + cv2.IMREAD_ANYDEPTH
# img_depth_lst = [cv2.imread(name, depth_read_flags) for name in depth_names]  # loads a dtype=uint8 array

# #----------------
# # Initialize object pose (aws sequences)
# body2color_pose = np.array([1, 0,  0, 0,
#                              0, 0, -1, 0,
#                              0, 1,  0, 0.456,
#                              0, 0,  0, 1 ]).reshape((4,4))
# dR_l = quaternion.as_rotation_matrix(quaternion.from_rotation_vector([0.2,0,0.0]))
# body2color_pose[:3,:3] = body2color_pose[:3,:3] @ dR_l
# #----------------

# # wb = wc*cb
# body2world_pose = color2world_pose @ body2color_pose 

# SLEEP = int(1000/30)  # frames at 30 Hz

# print('\n------\nPress q to quit during execution')
# print('Press any other key to step to next image')


# # Simulate one iteration of Tracker::RunTrackerProcess for loop
# for i, (img_bgr, img_depth) in enumerate(zip(img_bgr_lst, img_depth_lst)):
#     t1 = time.time()
#     print('\nIteration: ', i)
#     # 1) Update camera image -> replaces a call to the camera UpdateImage method (which does nothing for Dummy(Color|Depth)Camera) 
#     color_camera.image = img_bgr
#     ok = tracker.UpdateCameras(True)  # poststep verifying the images have been properly setup
#     if not ok:
#         raise ValueError('Something is wrong with the provided images')

#     if i == 0:
#         # 2) Use external init to update initial object pose
#         body.body2world_pose = body2world_pose  # simulate external initial pose

#     # 3) One tracking cycle
#     t = time.time()
#     tracker.ExecuteTrackingStep(i)
#     print('ExecuteTrackingCycle (ms)', 1000*(time.time() - t))
#     print('body.body2world_pose\n',body.body2world_pose)

#     # 4) Render results
#     t = time.time()
#     # color_viewer.UpdateViewer(i)
#     # if args.use_depth and args.use_depth_viewer:
#     #     depth_viewer.UpdateViewer(i)
#     # print('Updating viewers took (ms)', 1000*(time.time() - t))
    
#     if args.stop_at_each_img:
#         k = cv2.waitKey(0)
#     else:
#         delay = time.time() - t1
#         sleep = max(1, SLEEP - int(1000*delay))
#         k = cv2.waitKey(sleep)
#     if k == ord('q'):
#         break
